---
title: "Comparing mGP and tIWP2"
author: "Ziang Zhang"
date: "2024-06-27"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## **Introduction**

There are two ways to parametrize a GP prior that penalizes the function $g$ toward the monotone base model $\text{span}\{1,m(x)\}$ where $m(x)$ is a monotonically increasing function such that $m'(x)>0$ for all $x \in \Omega$.

The first way is to use the M-GP prior. Let $\alpha(x) = \frac{m''(x)}{m'(x)}$ denotes the relative curvature function, then the M-GP prior is defined as
$$
L_\alpha g(x) := D^2 g(x) - \alpha(x) D g(x) = \sigma\xi(x).
$$

An alternative method is to use the transformed IWP2 prior (t-IWP2). 
The IWP-2 is defined as:
$$
D^2 \tilde{g}(x^*) = \sigma\xi(x^*).
$$
So it has base model being $\text{span}\{1, x^*\}$. 
By transforming the coordinate $x^* = m(x)$, we can obtain the t-IWP2 prior as $g(x) = \tilde{g}(m(x))$. 
The base model of t-IWP2 is therefore $\text{span}\{1, m(x)\}$, which is the same as the M-GP prior.


## **SDE characterization of the t-IWP2**

To conceptually compare the two priors, we can consider the SDE characterization of the t-IWP2 prior.

\begin{equation}
\begin{aligned}
g'(x) &= \tilde{g}'(m(x)) m'(x).\\
g''(x) &= \tilde{g}''(m(x)) m'(x)^2 + \tilde{g}'(m(x)) m''(x) \\
&= \tilde{g}''\left(m(x)\right) m'(x)^2 + g'(x) \frac{m''(x)}{m'(x)} \\
&= \tilde{g}''\left(m(x)\right) m'(x)^2 + g'(x) \alpha(x).
\end{aligned}
\end{equation}
Therefore we have:
$$L_\alpha g(x) = \tilde{g}''\left(m(x)\right) m'(x)^2.$$

Note that $\tilde{g}''\left(m(x)\right) m'(x)^2 = \tilde{g}''\left(m(x)\right) m'(x)^{1/2} m'(x)^{3/2}$, and that $\tilde{g}''\left(m(x)\right) m'(x)^{1/2} = \sigma\xi(x)$ (Claim 1, proof attached later). We can then write the SDE of the t-IWP2 prior as:
$$
L_\alpha g(x) = [\sigma m'(x)^{3/2}]\xi(x).
$$


Equivalently, we can move the extra $m'(x)^{3/2}$ to the left hand side and define a new operator $L_\alpha^* = m'(x)^{-3/2} L_\alpha$ and then $L_\alpha^*g(x) = \sigma\xi(x)$. 
It is then obvious that the t-IWP2 prior is (almost) equivalent to the M-GP prior, except the scaling factor $\sigma m'(x)^{-3/2}$ on the differential operator.
The effect of this scaling factor essentially changes the constant $\sigma$ in the M-GP prior to a function of $x$ in the t-IWP2 prior (i.e. $\sigma(x) = [\sigma m'(x)^{3/2}]$).
This implies comparing to the M-GP prior, the t-IWP2 prior has a more flexible penalty strength that can vary with $x$.
When the function is changing fast ($m'$ is large), the t-IWP2 prior has a small penalty and allows the function to deviate more from the base model than M-GP.


### ***Proof of Claim 1: $\tilde{g}''\left(m(x)\right) m'(x)^{1/2} = \xi(x)$***

Without the loss of generality, let's assume $\sigma = 1$ and let $x^* = m(x)$.
To show $\tilde{g}''\left(m(x)\right) m'(x)^{1/2} = \xi(x)$, we first notice that $\tilde{g}''\left(m(x)\right) m'(x)^{1/2} = \xi(m(x)) m'(x)^{1/2}$ as $\tilde{g}$ is an IWP2.

For any $g_1, g_2 \in L^2$, we have:
\begin{equation}
\begin{aligned}
\int \xi(m(x)) m'(x)^{1/2} g_1(x) dx &= \int \xi(x^* ) m'(m^{-1}(x^* ))^{-1/2} g_1(m^{-1}(x^* ))  dx^*  \\
&= \int \xi(x^* ) m'(x^* )^{-1/2} g_1(m^{-1}(x^*)) dx. \\
\end{aligned}
\end{equation}

Therefore, using property of Gaussian white noise $\xi(x^*)$, we have:
\begin{equation}
\begin{aligned}
\text{Cov}\bigg[\int\xi(m(x)) m'(x)^{1/2} g_1(x)dx, \int \xi(m(x)) m'(x)^{1/2} g_2(x)dx  \bigg]
&= \text{Cov}\bigg[\int\xi(x^* ) m'(m^{-1}(x^* ))^{-1/2} g_1(m^{-1}(x^* ))dx^* , \int \xi(x^* ) m'(x^* )^{-1/2} g_2(m^{-1}(x^* ))dx^*  \bigg] \\
&= \int m'(m^{-1}(x^* ))^{-1} g_1(m^{-1}(x^* )) g_2(m^{-1}(x^* )) dx^* \\
&= \int g_1(x) g_2(x) dx \\
&= \text{Cov}\bigg[\int\xi(x) g_1(x)dx, \int \xi(x) g_2(x)dx  \bigg].
\end{aligned}
\end{equation}
The proof is hence complete.



## **Comparison of samples**

### When $m(x) = \sqrt(x+c)$:

```{r message=FALSE, warning=FALSE, echo=TRUE}
library(tidyverse)
library(Matrix)
source("code/01-state-space.R")
source("code/02-FEM.R")
source("code/03-sampling.R")
```


To compare the two priors, we can simulate samples from the two priors and compare the samples when $m(x) = \sqrt x$.

For the M-GP prior:
```{r}
B = 100
c <- 1.1
m <- function(x) {sqrt(x+c)}
m_deriv <- function(x) {1/(2*sqrt(x+c))}

samps0 <- mGP_sim(mesh_size = 0.1, max_t = 10, alpha = (2), c = c, initial_vec = c(m(0),m_deriv(0)), sd = 0.1)
result0 <- samps0[,1:2]
for (i in 1:B) {
  samps0 <- mGP_sim(mesh_size = 0.1, max_t = 10, alpha = (2), c = c, initial_vec = c(m(0),m_deriv(0)), sd = 0.1)
  result0 <- cbind(result0, samps0[,2])
}
# result0[1:nrow(result0),-1] <- result0[1:nrow(result0),-1]/sd(result0[nrow(result0),-1])
matplot(x = result0[,1], y = result0[,-1], type = 'l', ylab = "Post Samp", xlab = "x", main = "alpha = 2", ylim = c(0,8), lty = "dashed", col = "pink")
lines(x = result0[,1], y = m(result0[,1]), col = "black", lty = "solid")
```

For the t-IWP2 prior:
```{r}
# set the original grid
t <- seq(0, 10, by = 0.1)
# compute the transformed grid
t_trans <- m(t)

# sampling from tIWP2
samps1 <- sim_IWp_Var(t = t_trans, p = 2, sd = 0.1, initial_vec = c(m(0),1))
result1 <- cbind(c(t), samps1[,2])
for (i in 1:B) {
  samps1 <- sim_IWp_Var(t = t_trans, p = 2, sd = 0.1, initial_vec = c(m(0),1))
  result1 <- cbind(result1, samps1[,2])
}
# result1[1:nrow(result1),-1] <- result1[1:nrow(result1),-1]/sd(result1[nrow(result1),-1])
matplot(x = result1[,1], y = result1[,-1], type = 'l', ylab = "Post Samp", xlab = "x", main = "tIWP2", ylim = c(0,8), lty = "dashed", col = "pink")
lines(x = result1[,1], y = m(result1[,1]), col = "black", lty = "solid")
```

Compare the variance of the two priors:
```{r}
## Variance of overtime:
var0 <- apply(result0[,-1], 1, var)
var1 <- apply(result1[,-1], 1, var)
plot(x = result0[,1], y = var0, type = 'l', ylab = "Variance", xlab = "x", main = "Variance of samples", ylim = c(0,5), lty = "dashed", col = "pink")
lines(x = result1[,1], y = var1, col = "black", lty = "solid")
```

### When $m(x) = (x+c)^3$:


```{r}
m <- function(x) {(x+c)^3}
m_deriv <- function(x) {3*(x+c)^2}
samps0 <- mGP_sim(mesh_size = 0.1, max_t = 10, alpha = (-1/2), c = c, initial_vec = c(m(0),m_deriv(0)), sd = 0.1)
result0 <- samps0[,1:2]
for (i in 1:B) {
  samps0 <- mGP_sim(mesh_size = 0.1, max_t = 10, alpha = (-1/2), c = c, initial_vec = c(m(0),m_deriv(0)), sd = 0.1)
  result0 <- cbind(result0, samps0[,2])
}
matplot(x = result0[,1], y = result0[,-1], type = 'l', ylab = "Post Samp", xlab = "x", main = "alpha = -1/2", lty = "dashed", col = "pink")
lines(x = result0[,1], y = m(result0[,1]), col = "black", lty = "solid")
```

```{r}
# set the original grid
t <- seq(0, 10, by = 0.1)
# compute the transformed grid
t_trans <- m(t)
# sampling from tIWP2
samps1 <- sim_IWp_Var(t = t_trans, p = 2, sd = 0.1, initial_vec = c(m(0),1))
result1 <- cbind(c(t), samps1[,2])
for (i in 1:B) {
  samps1 <- sim_IWp_Var(t = t_trans, p = 2, sd = 0.1, initial_vec = c(m(0),1))
  result1 <- cbind(result1, samps1[,2])
}
matplot(x = result1[,1], y = result1[,-1], type = 'l', ylab = "Post Samp", xlab = "x", main = "tIWP2", lty = "dashed", col = "pink")
lines(x = result1[,1], y = m(result1[,1]), col = "black", lty = "solid")
```

Compare the variance of the two priors:
```{r}
## Variance of overtime:
var0 <- apply(result0[,-1], 1, var)
var1 <- apply(result1[,-1], 1, var)
plot(x = result0[,1], y = var0, type = 'l', ylab = "Variance", xlab = "x", main = "Variance of samples", ylim = c(0,1000), lty = "dashed", col = "pink")
lines(x = result1[,1], y = var1, col = "black", lty = "solid")
```

